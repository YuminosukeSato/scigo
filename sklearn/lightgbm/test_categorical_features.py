#!/usr/bin/env python3
"""
LightGBMã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ã®Goå®Ÿè£…æ¤œè¨¼ãƒ†ã‚¹ãƒˆ

ã“ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆã¯ã€Goã§å®Ÿè£…ã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ãŒ
Python LightGBMã¨åŒç­‰ã®å‹•ä½œã‚’ã™ã‚‹ã“ã¨ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚
"""

import numpy as np
import pandas as pd
import lightgbm as lgb
import json
import os
from typing import Dict, List, Tuple


def create_categorical_dataset(n_samples: int = 200, seed: int = 42) -> Tuple[pd.DataFrame, np.ndarray]:
    """
    ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ãŒæ±ºå®šçš„ãªæ„å‘³ã‚’æŒã¤ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ
    
    Args:
        n_samples: ã‚µãƒ³ãƒ—ãƒ«æ•°
        seed: ä¹±æ•°ã‚·ãƒ¼ãƒ‰
        
    Returns:
        X: ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        y: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé…åˆ—
    """
    np.random.seed(seed)
    
    # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡: A,B -> ã‚¯ãƒ©ã‚¹0ã€C,D -> ã‚¯ãƒ©ã‚¹1 ã«å¼·ãé–¢é€£
    cat_values = ['A', 'B', 'C', 'D']
    cat_feat = np.random.choice(cat_values, n_samples)
    
    # æ•°å€¤ç‰¹å¾´é‡: å¼±ã„ãƒã‚¤ã‚ºã¨ã—ã¦è¿½åŠ ï¼ˆã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ã‚ˆã‚Šé‡è¦åº¦ã‚’ä¸‹ã’ã‚‹ï¼‰
    num_feat1 = np.random.randn(n_samples) * 0.1
    num_feat2 = np.random.randn(n_samples) * 0.05
    
    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: ã‚«ãƒ†ã‚´ãƒªã«ã‚ˆã£ã¦å¼·ãæ±ºå®šã•ã‚Œã‚‹
    y = np.zeros(n_samples)
    # A,B -> 0.1ã®ç¢ºç‡ã§1ã€C,D -> 0.9ã®ç¢ºç‡ã§1
    for i, cat in enumerate(cat_feat):
        if cat in ['A', 'B']:
            y[i] = np.random.choice([0, 1], p=[0.95, 0.05])
        else:  # C, D
            y[i] = np.random.choice([0, 1], p=[0.05, 0.95])
    
    # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ã‚’æ•°å€¤ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    cat_mapping = {'A': 0, 'B': 1, 'C': 2, 'D': 3}
    cat_feat_encoded = np.array([cat_mapping[cat] for cat in cat_feat])
    
    df = pd.DataFrame({
        'num_feat1': num_feat1,
        'num_feat2': num_feat2,
        'cat_feat': cat_feat_encoded
    })
    
    return df, y


def test_categorical_split_detection():
    """ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«åˆ†å‰²ãŒæ­£ã—ãæ¤œå‡ºã•ã‚Œã‚‹ã‹ãƒ†ã‚¹ãƒˆ"""
    X, y = create_categorical_dataset(n_samples=100)
    
    # LightGBMã§å­¦ç¿’
    lgb_train = lgb.Dataset(X, y, categorical_feature=['cat_feat'])
    lgb_model = lgb.train(
        params={
            'objective': 'binary',
            'metric': 'binary_logloss',
            'num_leaves': 4,
            'min_data_in_leaf': 5,
            'verbose': -1
        },
        train_set=lgb_train,
        num_boost_round=1  # 1ã¤ã®ãƒ„ãƒªãƒ¼ã®ã¿å­¦ç¿’
    )
    
    # ãƒ„ãƒªãƒ¼æ§‹é€ ã‚’è§£æ
    tree_df = lgb_model.trees_to_dataframe()
    print(f"ãƒ„ãƒªãƒ¼æ§‹é€ :\n{tree_df.head(10)}")
    
    # åˆ†å‰²ãƒãƒ¼ãƒ‰ãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
    internal_nodes = tree_df[tree_df['split_feature'].notna()]
    assert len(internal_nodes) > 0, "åˆ†å‰²ãƒãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
    
    # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«åˆ†å‰²ãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
    categorical_splits = tree_df[tree_df['split_feature'] == 'cat_feat']
    print(f"ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«åˆ†å‰²æ•°: {len(categorical_splits)}")
    
    if len(categorical_splits) > 0:
        print("âœ… ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«åˆ†å‰²ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
    else:
        print("âš ï¸  ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«åˆ†å‰²ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        # ä»–ã®ç‰¹å¾´é‡ã§ã®åˆ†å‰²ã‚’ç¢ºèª
        feature_splits = tree_df['split_feature'].value_counts()
        print(f"ç‰¹å¾´é‡åˆ¥åˆ†å‰²æ•°:\n{feature_splits}")
    
    print("âœ… ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«åˆ†å‰²æ¤œå‡ºãƒ†ã‚¹ãƒˆ: PASS")
    return tree_df


def test_optimal_categorical_grouping():
    """æœ€é©ãªã‚«ãƒ†ã‚´ãƒªã‚°ãƒ«ãƒ¼ãƒ—åˆ†ã‘ãŒè¡Œã‚ã‚Œã‚‹ã‹ãƒ†ã‚¹ãƒˆ"""
    X, y = create_categorical_dataset(n_samples=300)
    
    # æœŸå¾…ã•ã‚Œã‚‹åˆ†å‰²: {A, B} vs {C, D}
    expected_group1 = {'A', 'B'}  # ã‚¯ãƒ©ã‚¹0ã«å¯¾å¿œ
    expected_group2 = {'C', 'D'}  # ã‚¯ãƒ©ã‚¹1ã«å¯¾å¿œ
    
    # LightGBMã§å­¦ç¿’
    lgb_train = lgb.Dataset(X, y, categorical_feature=['cat_feat'])
    lgb_model = lgb.train(
        params={
            'objective': 'binary',
            'metric': 'binary_logloss',
            'num_leaves': 4,
            'min_data_in_leaf': 10,
            'verbose': -1
        },
        train_set=lgb_train,
        num_boost_round=1
    )
    
    # ãƒ„ãƒªãƒ¼æ§‹é€ ã‚’è§£æ
    tree_df = lgb_model.trees_to_dataframe()
    cat_splits = tree_df[tree_df['split_feature'] == 'cat_feat']
    
    if len(cat_splits) > 0:
        # LightGBMã®ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«åˆ†å‰²ã®è§£æ
        for _, split in cat_splits.iterrows():
            threshold = split['threshold']
            print(f"ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«åˆ†å‰²ã®threshold: {threshold}")
            print(f"Splitæ¡ä»¶: {split['decision_type']}")
    
    print("âœ… æœ€é©ã‚«ãƒ†ã‚´ãƒªã‚°ãƒ«ãƒ¼ãƒ—åˆ†ã‘ãƒ†ã‚¹ãƒˆ: PASS")
    return tree_df


def create_go_test_data():
    """Goå®Ÿè£…ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
    X, y = create_categorical_dataset(n_samples=50, seed=123)
    
    # ã‚«ãƒ†ã‚´ãƒªã‚’æ•°å€¤ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    cat_mapping = {'A': 0, 'B': 1, 'C': 2, 'D': 3}
    X_encoded = X.copy()
    X_encoded['cat_feat'] = X_encoded['cat_feat'].map(cat_mapping)
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä¿å­˜
    test_data = {
        'X': X_encoded.values.tolist(),
        'y': y.tolist(),
        'categorical_features': [2],  # cat_featã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        'feature_names': ['num_feat1', 'num_feat2', 'cat_feat'],
        'category_mapping': cat_mapping
    }
    
    with open('testdata/categorical_test_data.json', 'w') as f:
        json.dump(test_data, f, indent=2)
    
    print("âœ… Goå®Ÿè£…ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†")
    return test_data


def test_prediction_accuracy():
    """äºˆæ¸¬ç²¾åº¦ã®ãƒ†ã‚¹ãƒˆ"""
    X, y = create_categorical_dataset(n_samples=200)
    
    # è¨“ç·´/ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿åˆ†å‰²
    split_idx = int(len(X) * 0.7)
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    # LightGBMã§å­¦ç¿’
    lgb_train = lgb.Dataset(X_train, y_train, categorical_feature=['cat_feat'])
    lgb_model = lgb.train(
        params={
            'objective': 'binary',
            'metric': 'binary_logloss',
            'num_leaves': 8,
            'min_data_in_leaf': 5,
            'learning_rate': 0.1,
            'verbose': -1
        },
        train_set=lgb_train,
        num_boost_round=10
    )
    
    # äºˆæ¸¬
    y_pred = lgb_model.predict(X_test)
    y_pred_binary = (y_pred > 0.5).astype(int)
    
    # ç²¾åº¦è¨ˆç®—
    accuracy = np.mean(y_pred_binary == y_test)
    print(f"LightGBMäºˆæ¸¬ç²¾åº¦: {accuracy:.3f}")
    
    # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ã‚’æ­£ã—ãå­¦ç¿’ã§ãã¦ã„ã‚Œã°é«˜ç²¾åº¦ãŒæœŸå¾…ã•ã‚Œã‚‹
    assert accuracy > 0.75, f"äºˆæ¸¬ç²¾åº¦ãŒä½ã™ãã¾ã™: {accuracy}"
    
    print("âœ… äºˆæ¸¬ç²¾åº¦ãƒ†ã‚¹ãƒˆ: PASS")
    return accuracy


def analyze_categorical_importance():
    """ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ã®é‡è¦åº¦åˆ†æ"""
    X, y = create_categorical_dataset(n_samples=300)
    
    # LightGBMã§å­¦ç¿’
    lgb_train = lgb.Dataset(X, y, categorical_feature=['cat_feat'])
    lgb_model = lgb.train(
        params={
            'objective': 'binary',
            'metric': 'binary_logloss',
            'num_leaves': 8,
            'min_data_in_leaf': 10,
            'verbose': -1
        },
        train_set=lgb_train,
        num_boost_round=5
    )
    
    # ç‰¹å¾´é‡é‡è¦åº¦
    importance = lgb_model.feature_importance(importance_type='gain')
    feature_names = lgb_model.feature_name()
    
    importance_dict = dict(zip(feature_names, importance))
    print("ç‰¹å¾´é‡é‡è¦åº¦:")
    for name, imp in importance_dict.items():
        print(f"  {name}: {imp:.3f}")
    
    # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ãŒæœ€ã‚‚é‡è¦ã«ãªã‚‹ã“ã¨ã‚’æœŸå¾…
    cat_importance = importance_dict.get('cat_feat', 0)
    max_importance = max(importance_dict.values())
    
    assert cat_importance == max_importance, "ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ãŒæœ€é‡è¦ã«ãªã£ã¦ã„ã¾ã›ã‚“"
    
    print("âœ… ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«é‡è¦åº¦åˆ†æ: PASS")
    return importance_dict


def main():
    """å…¨ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
    print("=== LightGBMã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ãƒ†ã‚¹ãƒˆé–‹å§‹ ===\n")
    
    # testdataãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    os.makedirs('testdata', exist_ok=True)
    
    try:
        # å„ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
        print("1. ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«åˆ†å‰²æ¤œå‡ºãƒ†ã‚¹ãƒˆ")
        test_categorical_split_detection()
        print()
        
        print("2. æœ€é©ã‚«ãƒ†ã‚´ãƒªã‚°ãƒ«ãƒ¼ãƒ—åˆ†ã‘ãƒ†ã‚¹ãƒˆ") 
        test_optimal_categorical_grouping()
        print()
        
        print("3. Goå®Ÿè£…ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ")
        create_go_test_data()
        print()
        
        print("4. äºˆæ¸¬ç²¾åº¦ãƒ†ã‚¹ãƒˆ")
        test_prediction_accuracy()
        print()
        
        print("5. ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«é‡è¦åº¦åˆ†æ")
        analyze_categorical_importance()
        print()
        
        print("ğŸ‰ å…¨ãƒ†ã‚¹ãƒˆå®Œäº†: SUCCESS")
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        raise


if __name__ == "__main__":
    main()